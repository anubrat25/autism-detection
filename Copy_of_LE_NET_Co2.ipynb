{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fHdyHkj5XaYC"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2VdhqbjMRE1",
        "outputId": "7ca3fc3f-d709-44e0-cec4-7fb4f7466ec6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vDWEclY_XaYE",
        "outputId": "cb6b8a63-4153-4251-cf16-d11bcf3222f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to read image: /content/drive/MyDrive/dataset/Autism/dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "data_dir = r\"/content/drive/MyDrive/dataset\"\n",
        "labels = ['Normal', 'Autism']\n",
        "img_size = 256\n",
        "\n",
        "def get_data(data_dir):\n",
        "    data = []\n",
        "    for label in labels:\n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_path = os.path.join(path, img)\n",
        "                img_arr = cv2.imread(img_path)\n",
        "                if img_arr is not None:\n",
        "                    img_arr = img_arr[...,::-1] # convert BGR to RGB format\n",
        "                    resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                    data.append([resized_arr, class_num])\n",
        "                else:\n",
        "                    print(f\"Failed to read image: {img_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing image {img_path}: {e}\")\n",
        "    return data\n",
        "\n",
        "# Load data from the dataset directory\n",
        "data = get_data(data_dir)\n",
        "\n",
        "# Prepare labels for visualization\n",
        "labels_list = []\n",
        "for i in data:\n",
        "    if i[1] == 0:\n",
        "        labels_list.append(\"Normal\")\n",
        "    elif i[1] == 1:\n",
        "        labels_list.append(\"Nutism\")\n",
        "\n",
        "# Visualize the distribution of labels\n",
        "sns.set_style('darkgrid')\n",
        "sns.countplot(labels_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1gnR6kU3XaYF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "images, labels_list = zip(*data)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "images = np.array(images)\n",
        "# Ensure labels are one-hot encoded\n",
        "labels_list = to_categorical(labels_list, num_classes=2)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels_list, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize pixel values\n",
        "X_train = X_train / 255.0\n",
        "X_val = X_val / 255.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0QqjYBhLXaYG"
      },
      "outputs": [],
      "source": [
        "# Building the Model Architecture\n",
        "model = Sequential()\n",
        "# Select 6 feature convolution kernels with a size of 5 * 5 (without offset), and get 66 feature maps. The size of each feature map is 32−5 + 1 = 2832−5 + 1 = 28.\n",
        "# That is, the number of neurons has been reduced from 10241024 to 28 ∗ 28 = 784 28 ∗ 28 = 784.\n",
        "# Parameters between input layer and C1 layer: 6 ∗ (5 ∗ 5 + 1)\n",
        "model.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(256,256,3)))\n",
        "# The input of this layer is the output of the first layer, which is a 28 * 28 * 6 node matrix.\n",
        "# The size of the filter used in this layer is 2 * 2, and the step length and width are both 2, so the output matrix size of this layer is 14 * 14 * 6.\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# The input matrix size of this layer is 14 * 14 * 6, the filter size used is 5 * 5, and the depth is 16. This layer does not use all 0 padding, and the step size is 1.\n",
        "# The output matrix size of this layer is 10 * 10 * 16. This layer has 5 * 5 * 6 * 16 + 16 = 2416 parameters\n",
        "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
        "# The input matrix size of this layer is 10 * 10 * 16. The size of the filter used in this layer is 2 * 2, and the length and width steps are both 2, so the output matrix size of this layer is 5 * 5 * 16.\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# The input matrix size of this layer is 5 * 5 * 16. This layer is called a convolution layer in the LeNet-5 paper, but because the size of the filter is 5 * 5, #\n",
        "# So it is not different from the fully connected layer. If the nodes in the 5 * 5 * 16 matrix are pulled into a vector, then this layer is the same as the fully connected layer.\n",
        "# The number of output nodes in this layer is 120, with a total of 5 * 5 * 16 * 120 + 120 = 48120 parameters.\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4000,activation=\"relu\"))\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "model.add(Dense(100,activation=\"relu\"))\n",
        "model.add(Dense(2, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7mEv0VakXaYG",
        "outputId": "30fa75c6-e2ea-4a86-8a63-efd095350ce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 252, 252, 6)       456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 126, 126, 6)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 122, 122, 16)      2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 61, 61, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 59536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4000)              238148000 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1000)              4001000   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               100100    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 242252174 (924.12 MB)\n",
            "Trainable params: 242252174 (924.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Train size: 346\n",
            "Test size: 87\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.optimizers.SGD(lr=0.000001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "\n",
        "train_ds=tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
        "test_ds=tf.data.Dataset.from_tensor_slices((X_val,y_val))\n",
        "\n",
        "\n",
        "def process_image(image,label):\n",
        "    image=tf.image.per_image_standardization(image)\n",
        "    image=tf.image.resize(image,(256,256))\n",
        "\n",
        "    return image,label\n",
        "\n",
        "\n",
        "\n",
        "train_ds_size=tf.data.experimental.cardinality(train_ds).numpy()\n",
        "test_ds_size=tf.data.experimental.cardinality(test_ds).numpy()\n",
        "print('Train size:',train_ds_size)\n",
        "print('Test size:',test_ds_size)\n",
        "\n",
        "\n",
        "\n",
        "train_ds=(train_ds\n",
        "          .map(process_image)\n",
        "          .shuffle(buffer_size=train_ds_size)\n",
        "          .batch(batch_size=32,drop_remainder=True)\n",
        "         )\n",
        "test_ds=(test_ds\n",
        "          .map(process_image)\n",
        "          .shuffle(buffer_size=test_ds_size)\n",
        "          .batch(batch_size=32,drop_remainder=True)\n",
        "         )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "print(len(y_train))\n",
        "print(len(X_train))\n",
        "print(len(y_val))\n",
        "print(len(X_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBEo8U0uPu3I",
        "outputId": "243df165-4d0d-4264-ecbe-76a5b6cdc99f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "346\n",
            "346\n",
            "87\n",
            "87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.metrics.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VIsBDPBBRDGF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhjCcSwPXaYG",
        "outputId": "d18bf081-f595-410c-f71a-c2e56524fe7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            " 3/10 [========>.....................] - ETA: 44s - loss: 38.3841 - accuracy: 0.5417"
          ]
        }
      ],
      "source": [
        "history=model.fit(\n",
        "    train_ds,\n",
        "    epochs=50,\n",
        "    validation_data=test_ds,\n",
        "    validation_freq=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ryALLyFXaYG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX6jaWfQXaYH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nITajVohXaYH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(50)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "predictions = model.predict_classes(x_val)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(classification_report(y_valA, predictions, target_names = ['CN60_69','MCI60_69']))\n",
        "\n",
        "cm = confusion_matrix(y_valA, predictions)\n",
        "sns.heatmap(cm, annot= True, fmt='d')\n",
        "\n",
        "print(cm)\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "cax = ax.matshow(cm)\n",
        "\n",
        "plt.title('Confusion matrix of the classifier')\n",
        "\n",
        "fig.colorbar(cax)\n",
        "\n",
        "ax.set_xticklabels([''] + labels)\n",
        "\n",
        "ax.set_yticklabels([''] + labels)\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "\n",
        "plt.ylabel('True')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(classification_report(y_valA, predictions, target_names = ['CN60_69','CN60_69']))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvDcB2RTXaYH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "-L1OCGLiXaYH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IryVZQxXaYH"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train3,y_train3,epochs = 50 , validation_data = (x_val3, y_val3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTJLQaEnXaYH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc3 = history.history['accuracy']\n",
        "val_acc3 = history.history['val_accuracy']\n",
        "loss3 = history.history['loss']\n",
        "val_loss3 = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(50)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc3, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc3, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss3, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss3, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "predictions3 = model.predict_classes(x_val3)\n",
        "\n",
        "print(classification_report(y_valC, predictions3, target_names = ['CN60_69','AD60_69']))\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(predictions3, y_valC)\n",
        "sns.heatmap(cm, annot= True, fmt='d')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmSZXTz6XaYI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjDwIZ-OXaYI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UPbcTawXaYI"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUo6iFomXaYI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLlgFPmOXaYI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAEVt1fSXaYI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9KJvOeWXaYI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}